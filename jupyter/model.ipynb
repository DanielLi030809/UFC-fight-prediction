{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fbccdb7-7460-4884-a91b-d4b4d4cfb4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36df2ac8-255c-4f54-9fa4-e4db4f53b230",
   "metadata": {},
   "source": [
    "# Step 1: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c16add-0cff-4bdc-96b5-7225de78652c",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56785614-4a53-493c-a189-20b1bb8b4cd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/fighter-stats-threading.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loads in the fighter-stats df\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m fighters \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/fighter-stats-threading.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m fighters\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/fighter-stats-threading.csv'"
     ]
    }
   ],
   "source": [
    "# Loads in the fighter-stats df\n",
    "fighters = pd.read_csv(\"data/fighter-stats-threading.csv\")\n",
    "fighters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fd5f4c-5e7c-484f-99b1-c32bcb672879",
   "metadata": {},
   "source": [
    "## Basic Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2ffe0b-7cfb-4895-a7c8-4c772fc73b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the record into w, l, d and make three new columns\n",
    "pattern = r\"Record:\\s(\\d+)-(\\d+)-(\\d+)\"\n",
    "fighters[['win', 'loss', 'draw']] = fighters['Record'].str.extract(pattern).astype(int)\n",
    "# Drop the record column\n",
    "fighters = fighters.drop('Record', axis=1)\n",
    "\n",
    "# Takes in height in ft and convert it to inches\n",
    "def convert_to_inches(string):\n",
    "    if pd.isna(string):\n",
    "         return string\n",
    "    string_list = string.split(\"'\")\n",
    "    ft = int(string_list[0].strip())\n",
    "    inches = int(string_list[1].replace(\"\\\"\", \"\").strip())\n",
    "    return ft * 12 + inches\n",
    "# Convert height to inches\n",
    "fighters['Height(inches)'] = fighters['Height(inches)'].apply(convert_to_inches) \n",
    "# Rename column names\n",
    "fighters = fighters.rename(columns={'Height(inches)': 'Height', 'Weight(lbs)': 'Weight', 'Reach(inches)': 'Reach'})\n",
    "\n",
    "# Convert DOB column to datetime\n",
    "fighters['DOB'] = pd.to_datetime(fighters['DOB'])\n",
    "# Calculate age\n",
    "today = datetime.today()\n",
    "fighters['DOB'] = fighters['DOB'].apply(lambda x: today.year - x.year - ((today.month, today.day) < (x.month, x.day)))\n",
    "# Rename DOB column to age\n",
    "fighters.rename(columns={'DOB': 'Age'}, inplace=True)\n",
    "\n",
    "# Convert percentages to float numbers\n",
    "def percentages_to_float(column):\n",
    "    return column.str.rstrip('%').astype(float) / 100\n",
    "fighters[['Str.Acc.', 'Str.Def', 'TD Acc.', 'TD Def.']] = fighters[['Str.Acc.', 'Str.Def', 'TD Acc.', 'TD Def.']].apply(percentages_to_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8def7b8-f960-4066-b158-6c7c8798e781",
   "metadata": {},
   "source": [
    "## Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8468b588-9ee7-4ff0-b7d2-92db5e74ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing height with weight class average height\n",
    "fighters['Height'] = fighters.groupby('Weight')['Height'].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "\n",
    "# Impute missing reach with weight class average reach\n",
    "fighters['Reach'] = fighters.groupby('Weight')['Reach'].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "\n",
    "# Drop rows with missing weight because it's a low percentage (2%)\n",
    "fighters = fighters[~fighters['Weight'].isnull()]\n",
    "\n",
    "# Impute missing stance value with the mode\n",
    "fighters['Stance'] = fighters['Stance'].fillna('Orthodox')\n",
    "\n",
    "# Every fight starts on the feet. If a fighter is has all the striking stats as 0,\n",
    "# that most likely mean the fighter is insignificant.\n",
    "# Therefore, we can just remove those fighters\n",
    "columns_to_check = ['SLpM.', 'Str.Acc.', 'SApM', 'Str.Def']\n",
    "fighters = fighters[(fighters['SLpM.'] > 0) & (fighters['Str.Acc.'] > 0) & (fighters['SApM'] > 0) & (fighters['Str.Def'] > 0)]\n",
    "fighters.drop('Age', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d45e95-e92b-4c5d-8008-314353d1dc03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fighters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7138f-b5b2-46af-a1c7-4df175c49326",
   "metadata": {},
   "source": [
    "## Missing Data Edge Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b4d4a4-fa6d-4461-a925-81f48a503abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some fighters are in their own weight because of their unique weight. We just simplay remove those 131 entries\n",
    "fighters = fighters[~fighters['Reach'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27ae8ac-de24-4956-ac91-bf3e6ac66794",
   "metadata": {},
   "source": [
    "I decided to drop the Stance column all together.\n",
    "If I were to perform one-hot encoding on this categorizal column, I would create 10 additional columns just for one feature, which might cause linear independence and might oversaturate the dimensions, impacting model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa8155-f524-408c-b879-08d55b03af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the stance column\n",
    "fighters.drop('Stance', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acc0b55-63fc-4731-af2e-fc6eaa1228e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fighters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c280b98-e516-483e-b522-b93e50e7c255",
   "metadata": {},
   "source": [
    "## Perform Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bf9170-33ea-47b7-bdea-205425a78b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the fights dataset that includes all the fight matchups\n",
    "fights = pd.read_csv(\"data/fight-matchups.csv\")\n",
    "fights.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd018ed1-b390-4963-8a84-943111623d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged the tables and rename them\n",
    "matchups = fights.merge(fighters, left_on = 'fighter1', right_on = 'Full Name')\n",
    "matchups = matchups.merge(fighters, left_on = 'fighter2', right_on = 'Full Name')\n",
    "matchups = matchups.drop(columns=['fighter1', 'fighter2', 'Full Name_x', 'Full Name_y'])\n",
    "matchups.columns\n",
    "matchups = matchups.rename(columns={'Height_x': 'height1', 'Weight_x': 'weight1', 'Reach_x': 'reach1', 'SLpM._x': 'slpm1', 'Str.Acc._x': 'stracc1', \n",
    "                                    'SApM_x': 'sapm1', 'Str.Def_x': 'strdef1', 'TD Avg._x': 'tdavg1', 'TD Acc._x': 'tdacc1', 'TD Def._x': 'tddef1',\n",
    "                                    'Sub. Avg._x': 'subavg1', 'win_x': 'win1', 'loss_x': 'loss1', 'draw_x': 'draw1'})\n",
    "matchups = matchups.rename(columns={'Height_y': 'height2', 'Weight_y': 'weight2', 'Reach_y': 'reach2', 'SLpM._y': 'slpm2', 'Str.Acc._y': 'stracc2', \n",
    "                                    'SApM_y': 'sapm2', 'Str.Def_y': 'strdef2', 'TD Avg._y': 'tdavg2', 'TD Acc._y': 'tdacc2', 'TD Def._y': 'tddef2',\n",
    "                                    'Sub. Avg._y': 'subavg2', 'win_y': 'win2', 'loss_y': 'loss2', 'draw_y': 'draw2'})\n",
    "display(matchups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335ab553-b5bf-4550-87ad-27eafc32a87f",
   "metadata": {},
   "source": [
    "## Flip the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194b07b-1eea-42b7-8287-aec73b64e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "half = len(matchups.columns) // 2  # Number of columns to split\n",
    "\n",
    "# The first half of the dataframe that contains only information for fighter1\n",
    "matchups_first_half = matchups.iloc[:, :half]  # First half\n",
    "\n",
    "# The second half of the dataframe that contains only information for fighter2\n",
    "matchups_second_half = matchups.iloc[:, half:]  # Second half\n",
    "\n",
    "# Flips them by putting the second half first\n",
    "matchups_reversed = pd.concat([matchups_second_half, matchups_first_half], axis=1)\n",
    "\n",
    "# Rename the columns\n",
    "matchups_reversed.columns = matchups.columns\n",
    "display(matchups_reversed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82673da-0433-46f3-b456-07e38961bd24",
   "metadata": {},
   "source": [
    "## Stack the two tables on top of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1429d4-2010-4ab0-9e02-e32cc5171d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups_total = pd.concat([matchups, matchups_reversed], ignore_index=True)\n",
    "display(matchups_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b818ef3c-23ad-4305-aa15-3a3c64bda62d",
   "metadata": {},
   "source": [
    "# Step 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b5ddd1-4e62-446d-a74a-90295ee5d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with 9 potential subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
    "ax1 = axes[0]\n",
    "ax2 = axes[1]\n",
    "ax3 = axes[2]\n",
    "\n",
    "# Create a scatter plot to see if a longer reach makes you a better striker\n",
    "ax1.scatter(x=matchups_total['reach1'], y=matchups_total['slpm1'])\n",
    "ax1.set_xlabel('Reach')\n",
    "ax1.set_ylabel('Strikes Landed Per Minute')\n",
    "ax1.set_title('Reach vs Striking Ability')\n",
    "\n",
    "# Create a overlay histogram to see the win distribution of the UFC roster\n",
    "ax2.hist(matchups_total['win1'], bins=20, alpha=0.5, color='g', edgecolor='black', label='Win', density=True)\n",
    "ax2.set_xlabel('Number of Wins')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.set_title('The Win Distribution of UFC fighters')\n",
    "ax2.legend()\n",
    "\n",
    "# Create a scatter plot to see the relationship between striking defense and strikes absorbed per minute\n",
    "ax3.scatter(x=matchups_total['strdef1'], y=matchups_total['sapm1'], color='orange')\n",
    "ax3.set_ylim(0, 20)\n",
    "ax3.set_title('Striking Defense vs Strikes Absorbed Per Minute')\n",
    "ax3.set_xlabel('Striking Defense')\n",
    "ax3.set_ylabel('Strikes Absorbed Per Minute')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af8db70-9552-496f-9542-0994fd83f607",
   "metadata": {},
   "source": [
    "## Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0754faa-b1d5-4276-bb71-cf4428f59845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the correlation matrix\n",
    "correlation_matrix = matchups_total.corr()\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "# Use the correlation matrix to plot the heat map\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33fa517-ccce-4c28-9c21-6c3e09d78057",
   "metadata": {},
   "source": [
    "## Heatmap Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaed5bb5-3908-4283-b8a3-a59b93231203",
   "metadata": {},
   "source": [
    "1. Eliminate the win and draw columns. Having all win, loss, and draw create multicollinearity. I believe that loss is more important because wins are inflated since most fighters have lots of wins before coming to the ufc.\n",
    "2. Drop the weight, reach, and height columns, and use their differences instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7d44d6-9c72-4cdc-b910-6ae991ea63da",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac527c6c-69a8-437c-82a0-3185717e96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca0bd4-f292-4af2-93c3-8df10f940d4c",
   "metadata": {},
   "source": [
    "## Create target variable and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d45bbb-db73-406a-b856-1fe9af314069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate half of the number of rows of the data frame\n",
    "n = len(matchups_total) // 2\n",
    "\n",
    "# Create n number of ones and n number of zeros and put them in a series\n",
    "arr = np.concatenate([np.ones(n), np.zeros(n)])\n",
    "\n",
    "# Convert it to a Pandas Series\n",
    "series = pd.Series(arr)\n",
    "\n",
    "# Create the X and Y dataset\n",
    "X = matchups_total\n",
    "y = series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4e6e46-6ce3-483d-a788-5bfd3a31ec48",
   "metadata": {},
   "source": [
    "## Custom Transformation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b9a009-aac8-4df6-8c41-b7d7ed997e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom data transformation class to apply the heat map conclusions\n",
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Drop the win and draw columns\n",
    "        X = X.drop(columns=['win1', 'draw1', 'win2', 'draw2'])\n",
    "\n",
    "        # Difference in the amount of losses\n",
    "        X['loss_difference'] = X['loss1'] - X['loss2']\n",
    "\n",
    "        # Drop the loss columns\n",
    "        X.drop(columns=['loss1', 'loss2'])\n",
    "\n",
    "        # Drop the striking defense, and keep only strikes absorbed per minute column\n",
    "        X = X.drop(columns=['strdef1', 'strdef2'])\n",
    "        \n",
    "        # Difference in height (and drop individual columns)\n",
    "        X['height_difference'] = X['height1'] - X['height2']\n",
    "        X = X.drop(columns=['height1', 'height2'])\n",
    "        \n",
    "        # Drop the weight columns\n",
    "        X = X.drop(columns=['weight1', 'weight2'])\n",
    "        \n",
    "        # Difference in reach (and drop individual columns)\n",
    "        X['reach_difference'] = X['reach1'] - X['reach2']\n",
    "        X = X.drop(columns=['reach1', 'reach2'])\n",
    "\n",
    "        # Create multiplication of different features\n",
    "        X['sapm_*'] = X['sapm1'] * X['sapm2']\n",
    "        X = X.drop(columns=['sapm1', 'sapm2'])\n",
    "\n",
    "        X['tdavg_*'] = X['tdavg1'] * X['tdavg2']\n",
    "        X = X.drop(columns=['tdavg1', 'tdavg2'])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587e844c-f318-4c2e-9056-2670cfa642db",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdaf8fc-7df2-42c0-aa6c-07bfc380efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff836863-68de-446d-897e-2dfd830e5990",
   "metadata": {},
   "source": [
    "## Create the pipeline and param_grid for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18665446-ae70-4fab-a6c4-13c0b9d02244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline with Feature Engineering, StandardScaler, PCA, and Logistic Regression\n",
    "pipeline = Pipeline([\n",
    "    # ('feature_engineering', FeatureEngineer()),   # Step 1: Feature Engineering\n",
    "    ('scaler', StandardScaler()),                # Step 2: Standardize the data\n",
    "    ('pca', PCA()),                              # Step 3: PCA (Dimensionality Reduction)\n",
    "    ('log_reg', LogisticRegression(penalty='l1', solver='liblinear'))  # Step 4: Lasso Logistic Regression (L1 penalty)\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(2, 29)),           # Number of PCA components\n",
    "    'log_reg__C': np.linspace(0.001, 10, 10)          # Regularization strength for Lasso Logistic Regression\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6655e5-6945-42d1-83e9-9e7f56af67cc",
   "metadata": {},
   "source": [
    "## Create the pipeline and param_grid for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db2df4-f7d9-4a85-a71b-ab2b4ded9af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline with Feature Engineering, StandardScaler, PCA, and XGB\n",
    "pipeline = Pipeline([\n",
    "    # ('feature_engineering', FeatureEngineer()),   # Step 1: Feature Engineering\n",
    "    ('scaler', StandardScaler()),                # Step 2: Standardize the data\n",
    "    ('pca', PCA()),                              # Step 3: PCA (Dimensionality Reduction)\n",
    "    ('xgb', xgb.XGBClassifier())                 # Step 4: XGBoost Classifier\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV (XGBoost-specific hyperparameters)\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(2, 29)),                  # Number of PCA components\n",
    "    'xgb__n_estimators': [50, 100],               # Number of boosting rounds\n",
    "    'xgb__learning_rate': [0.01, 0.1, 0.5],      # Learning rate for XGBoost\n",
    "    'xgb__max_depth': [3, 5, 7],                  # Maximum depth of trees\n",
    "    'xgb__subsample': [0.8, 1.0],                 # Fraction of samples for each tree\n",
    "    'xgb__colsample_bytree': [0.8, 1.0]           # Fraction of features for each tree\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff99545b-2e0b-4cf2-adb2-a32a10d86fa5",
   "metadata": {},
   "source": [
    "## Evaluate model with grid search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce5527-0879-4d43-bfe4-ee93bc02a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search (this will perform the feature engineering, scaling, PCA, and logistic regression)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Output the best parameters and best score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score (cross-validation): \", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Test Score: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb7fc0b-4160-4642-ac66-a63cf5572c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion Matrix, Precision, Recall, and F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a3d04-caad-42d9-b6f4-51c56958efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Creates the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1)\n",
    "\n",
    "# Create classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df006ed-9d5a-4629-8494-78c439bfbd51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(\u001b[43mY_test\u001b[49m, Y_pred))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89f5f454-f558-4ed0-94ae-47c82fd27c36",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fighters_standardized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ian \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mfighters_standardized\u001b[49m[fighters_standardized[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFull Name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlexander Volkov\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mravel()[\u001b[38;5;241m0\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(ian)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fighters_standardized' is not defined"
     ]
    }
   ],
   "source": [
    "ian = np.array(fighters_standardized[standardized['Full Name'] == 'Alexander Volkov']).ravel()[0: -1]\n",
    "print(ian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e088cf17-76f6-4f39-934d-ade93bb9dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shavkat = np.array(fighters_standardized[fighters_standardized['Full Name'] == 'Ciryl Gane']).ravel()[0: -1]\n",
    "print(shavkat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d1690-916d-425d-8186-16d3ba6cdc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "shavkat_versus_ian = np.append(shavkat, ian)\n",
    "shavkat_versus_ian = shavkat_versus_ian[np.newaxis, :]\n",
    "len(shavkat_versus_ian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc10d46e-0892-411d-aaea-a1b7f7b96c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(np.array(shavkat_versus_ian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c708d7-d5ab-49aa-8d04-101f9037c765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b37c37-5582-4f9e-99d9-b4a89abbf21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(xgb_clf, \"model.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09019e80-9e12-4e32-bbca-8b8c022b4335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train random forest classifier\n",
    "randomForest = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=20, random_state=42)\n",
    "randomForest.fit(X_train, Y_train)\n",
    "Y_pred = randomForest.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, Y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
